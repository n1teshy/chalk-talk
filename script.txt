Topics:
 - AI v/s ML
 - links:
 - - dijkstra (https://algorithm-visualization.netlify.app/dijkstra-algorithm/)
 - - a-star (https://nomad-navigator.netlify.app/)

 - Algorithms
 - links:
 - - sorting visualization (https://www.cs.usfca.edu/~galles/visualization/ComparisonSort.html)
 
 - Techniques used for machine learning
 - Neural networks
 - Language models
 - Huggingface
 - AbbVie OCR

Todos:
 - A function with a local variable that keeps adjusting itself


1. Intro

hello everyone, looking at the AI hype recently and having worked on an ML soution for AbbVie, we have decided to
give you guys a primer on AI and some tips and tricks I've gained in the past several months I spent on my AI adventures.
---------------------------------------------------------------------------------------------------------------------

2. AI vs ML

I've seen too many people using the phrase "AI/ML" too many times, so I'd like to clarify the difference first, any machine that
can make decisions is intelligent, this decision making can be hard coded using a lot of if-else blocks, e.g. if the tea is
colder than 60Â°C: drink it, else: let it cool down, or it can be learnt by the machine using some data driven algorithm, the
machine can look at the features of the data, in this case the temperature of the tea and decide if it safe for a human to
drink, but essentially, what we call intelligence in machines is the ability to make decisions, and we've had AIs for a long
time, the algorithms used by google maps to find the shortest path is intelligent, it makes a lot of decisions while finding the
path to your destination, the exact algorithms it uses for this task are dijkstra's shortest path algorithm and another called
A-star, the first one is quite simple and the second is based on a heuristic, I have made a web page to visualize how both
of these algorithms work so you don't have to imagine it, dijkstra is based on a very simple logic, it starts on a node, visits
the nearest connected nodes and then visits the nearest nodes to the previously visited nodes until it finds your destination,
a-star is a bit more complicated, it uses a heuristic, a trick, in the visualization the whole screen is divided into small
cells, you just can't see it, when you leave the worm at a cell all it knows about is the position of the destination, and
position of the cell it's on, and then it computes the distance from its neighboring cells to the destination and picks up
whichever cell has the least distance as the next cell and it keeps doing that until it reaches the destination, these are
just simple AI algorithms, there are more complicated algorithms to do more complicated things, like deciding who is eligible
for bank loans, which group of stocks has the best profit margin, what content a user might like on instagram and so on.

If we've had AIs for so long why the sudden hype now? the algorithms we talked about are using hard coded decision making,
while it works for simple tasks like finding the shortest path between two points, it's not a viable solution for something
like language modeling, language modeling as the phrase says means modeling the intricacies of language, the grammar, order
of words, punctuation etc, you can't write if-else blocks for every pattern of questions that may be present in a question,
for a task like this, the ideal solution would be a system that can learn on its own, and this ability of a machine to learn
on its own without you having to write code for every condition is called machine learning. The recent hype is more about
machine learning than AI as a whole because after a long while, maybe a few decades, we finally have the compute, data and
research to get machines to learn more and more complicated tasks.
---------------------------------------------------------------------------------------------------------------------

- Algorithms
TODO: this section feels separated from its complementary partner

---------------------------------------------------------------------------------------------------------------------

3. Techniques used for machine learning

there have been lots of machine algorithms specific to tasks like making predictions and classifying things, linear regression
is used for making predictions and things like logistic regression, SVM and KNN are used for classification tasks, they're all
simple algorithms compared to the models we have now

linear regression:
linear regression finds a line that most accurately fits some points on graph(visualize it), it stores some parameters that
determine the line, so when you ask it to make a prediction for a point on the x-axis it can give you a range for the right
y-values.
the line equation is y = mx + c, x is the input and m and c are the parameters that detrmine the slope and y-intercept of
the line, so m and c are you parameters.

logistic regression:
logistic regression tries to draw decision boundaries to group things(visualize it), decision boundary is a curve on a graph
that creates a boundary between two areas, each area is a class, it also stores parameters to mold this curve into a shape
that most accurately classifies the data.

KNN:
KNN is an impostor among these
algorthms, it's lazy, it stores a lot of samples of different classes and when you give it an unlabeled input, it just looks
at the stored samples and their distance from the new input, and it outputs the class of samples that are closest to the new
input(visualize it).
---------------------------------------------------------------------------------------------------------------------

4. Neural networks

despite their relative simplicity, these algorithms have achieved decent successes in their respective fields, linear
regression is used to predict optimal prices for homes in real estate, to predict stock prices and determine the optimal
credit score for getting loans and logistic regression is used to detect fraudulent transactions and emails but they
are very limited in their capacities, linear and logistic regression can only model linear relationships, what that means is
they have an additive effect on the input, what that means is the output is highly dependant on the input, if the input
increases output increases, if input decreases the output decreases, they have a 1:1 correspondence to the input, for example
a smile generally means something positive, if you run a linear regression model on a lot of smiles, it might tell you
"the wider the smile, the more positive the situation is", but as your survival instincts will tell you, after a certain point,
wide smiles start looking creepy and your legs start moving quicker, in this problem, the input, i.e. the size of smile, doesn't
have a 1:1 correspondence to the situation, it's more complicated than that, more concretely, the input has a non-linear
relationship with the output, models like linear regression can't model complicated patterns like this, this is a neural
network's job.

in a single line, not originally by me, "an artifical neural network is a mathematical abstraction of the brain", what it means
is, it does what your brain does, but instead of using biological neurons and chemical signals, it uses numbers and math,  
it's a mathematical copy of the brain, before explaining neural networks, I'd like to talk about the brain because neural
networks are heavily inspired by it, the essentially is a large network of neurons and they all have connections to each other
using which they transmit signals to one another, a single neuron can have thousands of connections to other neurons and the
total number of these connections is well over a 100 trillion, that's 1 followed by 14 zeros, nobody known exactly how your
head works but we have an educated guess, when you get a stimulus through your senses, like touching something or looking at
something, your senses capture some data and send it through the nerves in the spinal cord to the brain for processing, the
sensory data travels from one neuron to another in the form of chemical signals, it reaches the brain and the same thing
happens there, the signals travel from one neuron to another, but the neurons in the brain are highly specialized for cognition
and complex processing and have many more connections while the neurons in the other parts of body are mostly just used for
transfering signals from senses, so, the brain processes the sensory signals and sends a signal back the muscles and that
signal in turn moves your body in response to the stimulus. So, we've got a good guess, sensory input travels from senses to
the brain in the form of a signal, the brain processes it by passing it through a long sequence of neurons, and in the end it
becomes a signal that goes back to the muscles, think of these two signals as input and output, people also found out that
the strength of these signals doesn't remain the same throughout the processes, some neurons fire more intensely than others
so the neurons must be doing some processing and it makes sense, if all neurons do is pass a signal as it is, there is nothing
interesting happening.

here is a masterful drawing depicting all of it
sensory input travels to brain -> neuron1-process -> neuron2-process -> neuron3-process -> muscle moves

now we'll see how people imitated all this with neural networks, we used weighted nodes to imitate neurons, a weighted node
is a node with two numbers a weight and a bias, a node can be expressed using a simple function i.e. f(x) = W.x + b, it
it takes a number, multiplies the number with the weight and adds the bias, this is the mathematical approximation of A
biological neuron's processing of chemical signals, after doing this, the node passes the output to another node as the
other node's input, and this keeps going till the end of the neural network

it can be expressed like this:
input x -> neuron1(x) = W1.x + b1 -> neuron2(x) = W2.x + b2 -> neuron3(x) = W3.x + b3 -> output y

the represenatational capability of the network can be increase by increasing the number of parameters in it like this

  /â¾ neuron1(x: W1.x + b1) = x1 -> neuron2(x1: W2.x1 + b2) = x2 -> neuron3(x2: W3.x2 + b3) = x3 â¾\
x                                                                                                 + -> y
  \_ neuron1(x: W1.x + b1) = x1 -> neuron2(x1: W2.x1 + b2) = x2 -> neuron3(x2: W3.x2 + b3) = x3 _/

---------------------------------------------------------------------------------------------------------------------

5. Language models

So, neural networks are these machines that can learn to predict the desired numerical output for a numerical input, by
adjusting their local variables or parameters as they're called in fancyland, 
